{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/intro-to-nlp/blob/master/course_project_2023_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucyWlC5gbOyR"
      },
      "source": [
        "# Introduction to HLT Project (Template)\n",
        "\n",
        "- Student(s) Name(s):\n",
        "- Date:\n",
        "- Chosen Corpus:\n",
        "- Contributions (if group project):\n",
        "\n",
        "### Corpus information\n",
        "\n",
        "- Description of the chosen corpus: Large Movie Review Dataset. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\n",
        "- Paper(s) and other published materials related to the corpus: \n",
        "\n",
        "State-of-the-art leaderboard: https://paperswithcode.com/sota/sentiment-analysis-on-imdb\n",
        "\n",
        "Related sentiment analysis paper: Sentiment Analysis for Movies Reviews Dataset Using Deep Learning Models Nehal Mohamed Ali, Marwa Mostafa Abd El Hamid and Aliaa Youssif\n",
        "\n",
        "- State-of-the-art performance (best published results) on this corpus:\n",
        "\n",
        "1\n",
        "RoBERTa-large with LlamBERT\n",
        "96.68\n",
        "LlamBERT: Large-scale low-cost data annotation in NLP\n",
        "2024\n",
        "\n",
        "2\n",
        "RoBERTa-large\n",
        "96.54\n",
        "LlamBERT: Large-scale low-cost data annotation in NLP\n",
        "2024\n",
        "\n",
        "3\n",
        "XLNet\n",
        "96.21\n",
        "XLNet: Generalized Autoregressive Pretraining for Language Understanding\n",
        "2019\n",
        "Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5d-9uxrcDY-"
      },
      "source": [
        "---\n",
        "\n",
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "caHHQoqEcG1J"
      },
      "outputs": [],
      "source": [
        "# Your code to install and import libraries etc. here\n",
        "import datasets \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import torch \n",
        "import transformers\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovUapilSb8iT"
      },
      "source": [
        "---\n",
        "\n",
        "## 2. Data download and preprocessing\n",
        "\n",
        "### 2.1. Download the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "PDx40YyzbGPc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Couldn't find cache for imdb for config 'default'\nAvailable configs in the cache: ['plain_text']",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[64], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Your code to download the corpus here\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimdb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#load the dataset from cache\u001b[39;00m\n\u001b[0;32m      4\u001b[0m display(dset)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\datasets\\load.py:2556\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2551\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[0;32m   2552\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[0;32m   2553\u001b[0m )\n\u001b[0;32m   2555\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 2556\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m load_dataset_builder(\n\u001b[0;32m   2557\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m   2558\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   2559\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[0;32m   2560\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[0;32m   2561\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   2562\u001b[0m     features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m   2563\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[0;32m   2564\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[0;32m   2565\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   2566\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   2567\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   2568\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m   2569\u001b[0m     _require_default_config_name\u001b[38;5;241m=\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2570\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_kwargs,\n\u001b[0;32m   2571\u001b[0m )\n\u001b[0;32m   2573\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   2574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\datasets\\load.py:2265\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[0;32m   2263\u001b[0m builder_cls \u001b[38;5;241m=\u001b[39m get_dataset_builder_class(dataset_module, dataset_name\u001b[38;5;241m=\u001b[39mdataset_name)\n\u001b[0;32m   2264\u001b[0m \u001b[38;5;66;03m# Instantiate the dataset builder\u001b[39;00m\n\u001b[1;32m-> 2265\u001b[0m builder_instance: DatasetBuilder \u001b[38;5;241m=\u001b[39m builder_cls(\n\u001b[0;32m   2266\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   2267\u001b[0m     dataset_name\u001b[38;5;241m=\u001b[39mdataset_name,\n\u001b[0;32m   2268\u001b[0m     config_name\u001b[38;5;241m=\u001b[39mconfig_name,\n\u001b[0;32m   2269\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[0;32m   2270\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[0;32m   2271\u001b[0m     \u001b[38;5;28mhash\u001b[39m\u001b[38;5;241m=\u001b[39mdataset_module\u001b[38;5;241m.\u001b[39mhash,\n\u001b[0;32m   2272\u001b[0m     info\u001b[38;5;241m=\u001b[39minfo,\n\u001b[0;32m   2273\u001b[0m     features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m   2274\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   2275\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   2276\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuilder_kwargs,\n\u001b[0;32m   2277\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_kwargs,\n\u001b[0;32m   2278\u001b[0m )\n\u001b[0;32m   2279\u001b[0m builder_instance\u001b[38;5;241m.\u001b[39m_use_legacy_cache_dir_if_possible(dataset_module)\n\u001b[0;32m   2281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\datasets\\packaged_modules\\cache\\cache.py:122\u001b[0m, in \u001b[0;36mCache.__init__\u001b[1;34m(self, cache_dir, dataset_name, config_name, version, hash, base_path, info, features, token, use_auth_token, repo_id, data_files, data_dir, storage_options, writer_batch_size, name, **config_kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhash\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m version \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# First we try to find a folder that takes the config_kwargs into account\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# e.g. with \"default-data_dir=data%2Ffortran\" as config_id\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     config_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBUILDER_CONFIG_CLASS(config_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcreate_config_id(\n\u001b[0;32m    120\u001b[0m         config_kwargs\u001b[38;5;241m=\u001b[39mconfig_kwargs, custom_features\u001b[38;5;241m=\u001b[39mfeatures\n\u001b[0;32m    121\u001b[0m     )\n\u001b[1;32m--> 122\u001b[0m     config_name, version, \u001b[38;5;28mhash\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_find_hash_in_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhash\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m version \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass both hash=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and version=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\datasets\\packaged_modules\\cache\\cache.py:48\u001b[0m, in \u001b[0;36m_find_hash_in_cache\u001b[1;34m(dataset_name, config_name, cache_dir)\u001b[0m\n\u001b[0;32m     38\u001b[0m         cached_directory_paths \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     39\u001b[0m             cached_directory_path\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m cached_directory_path \u001b[38;5;129;01min\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(cached_directory_path)\n\u001b[0;32m     44\u001b[0m         ]\n\u001b[0;32m     45\u001b[0m     available_configs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m     46\u001b[0m         {Path(cached_directory_path)\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m cached_directory_path \u001b[38;5;129;01min\u001b[39;00m cached_directory_paths}\n\u001b[0;32m     47\u001b[0m     )\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find cache for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for config \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_name \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAvailable configs in the cache: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavailable_configs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m available_configs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m     )\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# get most recent\u001b[39;00m\n\u001b[0;32m     54\u001b[0m cached_directory_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;28msorted\u001b[39m(cached_directory_paths, key\u001b[38;5;241m=\u001b[39m_get_modification_time)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
            "\u001b[1;31mValueError\u001b[0m: Couldn't find cache for imdb for config 'default'\nAvailable configs in the cache: ['plain_text']"
          ]
        }
      ],
      "source": [
        "# Your code to download the corpus here\n",
        "dset = datasets.load_dataset('imdb')\n",
        "#load the dataset from cache\n",
        "display(dset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXb7CQNCbZOI"
      },
      "source": [
        "### 2.2. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code for any necessary preprocessing here\n",
        "#Shuffle the dataset\n",
        "dset = dset.shuffle(seed=42)\n",
        "#Remove the unsupervised data part of the dataset as we dont need it for this task\n",
        "del dset['unsupervised']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RO5BXCuRbYKr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map (num_proc=4): 100%|██████████| 25000/25000 [00:06<00:00, 4134.59 examples/s]\n",
            "Map (num_proc=4): 100%|██████████| 25000/25000 [00:06<00:00, 4093.63 examples/s]\n"
          ]
        }
      ],
      "source": [
        "vectorizer = CountVectorizer(binary=True, max_features=25000)\n",
        "text_list = [i['text'] for i in dset['train']]\n",
        "vectorizer.fit(text_list)\n",
        "\n",
        "def vectorize_example(examples, vectorizer): \n",
        "    vectorized = vectorizer.transform([examples[\"text\"]])\n",
        "    non_zero = vectorized.nonzero()[1]\n",
        "    non_zero += 1\n",
        "    return {'input_ids': non_zero}\n",
        "\n",
        "# Conversion vocabulary \n",
        "idx2word = {v: k for k, v in vectorizer.vocabulary_.items()}\n",
        "\n",
        "tokenized_data = dset.map(vectorize_example, num_proc=4, fn_kwargs={'vectorizer': vectorizer})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['above', 'action', 'actress', 'allah', 'americana', 'anders', 'area', 'argument', 'atari', 'beulah', 'bother', 'butch', 'bye', 'characterisation', 'clairvoyant', 'classical', 'compared', 'complicating', 'criminal', 'englishman', 'enjoyment', 'evaluated', 'factions', 'faraway', 'fur', 'goodbye', 'handbook', 'haven', 'howard', 'ifc', 'isaac', 'italian', 'judged', 'justice', 'languages', 'likeable', 'looming', 'maine', 'mayberry', 'moreau', 'noah', 'notable', 'onassis', 'oral', 'others', 'peoples', 'plotline', 'plotted', 'policeman', 'preferable', 'primed', 'quits', 'realm', 'relations', 'serio', 'similarity', 'simpler', 'spirited', 'spotlight', 'superficiality', 'suspected', 'thank', 'thatch', 'theater', 'thereafter', 'thick', 'things', 'thinker', 'tho', 'toad', 'took', 'violently', 'wayans', 'weak', 'weaken', 'weirdos', 'writings']\n"
          ]
        }
      ],
      "source": [
        "test_row = tokenized_data['train'][0]['input_ids']\n",
        "convered_text = [idx2word[i] for i in test_row]\n",
        "print(convered_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collator(examples):\n",
        "    batch = {\"labels\":torch.tensor(list(example[\"label\"] for example in examples))}\n",
        "    tensors = []\n",
        "    max_len = max(len(example[\"input_ids\"]) for example in examples)\n",
        "    for example in examples:\n",
        "        ids = torch.tensor(example[\"input_ids\"])\n",
        "        padded = torch.nn.functional.pad(ids, (0, max_len - ids.shape[0]))\n",
        "        tensors.append(padded)\n",
        "    batch[\"input_ids\"] = torch.vstack(tensors)\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1ntHh_JbrAg"
      },
      "source": [
        "---\n",
        "\n",
        "## 3. Machine learning model\n",
        "\n",
        "### 3.1. Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hs2Bf49zbn5C"
      },
      "outputs": [],
      "source": [
        "# Your code to train the machine learning model on the training set and evaluate the performance on the validation set here\n",
        "\n",
        "class MLPConfig(transformers.PretrainedConfig):\n",
        "    pass\n",
        "class MLP(transformers.PreTrainedModel):\n",
        "    config_class=MLPConfig\n",
        "    def __init__(self,config):\n",
        "        super().__init__(config)\n",
        "        self.vocab_size=config.vocab_size #embedding matrix row count\n",
        "        self.embedding=torch.nn.Embedding(num_embeddings=self.vocab_size+1,embedding_dim=config.hidden_size,padding_idx=0)\n",
        "        torch.nn.init.uniform_(self.embedding.weight.data,-0.001,0.001) \n",
        "        self.output=torch.nn.Linear(in_features=config.hidden_size,out_features=config.nlabels)\n",
        "\n",
        "    def forward(self,input_ids,labels=None):\n",
        "        embedded=self.embedding(input_ids)\n",
        "        embedded_summed=torch.sum(embedded,dim=1)\n",
        "        projected=torch.tanh(embedded_summed) \n",
        "        logits=self.output(projected)\n",
        "        if labels is not None:\n",
        "            loss=torch.nn.CrossEntropyLoss()\n",
        "            return (loss(logits,labels),logits)\n",
        "        else:\n",
        "            return (logits,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlO8RVuHcmAh"
      },
      "source": [
        "### 3.2 Hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzDrTDd0cWOG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the latest cached version of the module from C:\\Users\\omarn\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--accuracy\\f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Sun Mar 31 18:07:34 2024) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'MLPConfig' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39mpredictions, references\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[0;32m     10\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m mlp_config\u001b[38;5;241m=\u001b[39m\u001b[43mMLPConfig\u001b[49m(vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(vectorizer\u001b[38;5;241m.\u001b[39mvocabulary_),hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,nlabels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     14\u001b[0m best_learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     15\u001b[0m best_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'MLPConfig' is not defined"
          ]
        }
      ],
      "source": [
        "# Your code for hyperparameter optimization here\n",
        "learning_rates = [1e-5, 1e-4, 1e-3, 1e-2]\n",
        "batch_sizes = [16, 32, 64, 128]\n",
        "\n",
        "def compute_accuracy(outputs_and_labels):\n",
        "    outputs, labels = outputs_and_labels\n",
        "    predictions = np.argmax(outputs, axis=-1) #pick the index of the \"winning\" label\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "mlp_config=MLPConfig(vocab_size=len(vectorizer.vocabulary_),hidden_size=20,nlabels=2)\n",
        "\n",
        "best_learning_rate = None\n",
        "best_batch_size = None\n",
        "best_accuracy = 0\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "        print(f\"Training with lr={lr} and batch_size={batch_size}\")\n",
        "        mlp=MLP(mlp_config)\n",
        "        trainer_args = transformers.TrainingArguments(\n",
        "            \"mlp_checkpoints\", #save checkpoints here\n",
        "            evaluation_strategy=\"steps\",\n",
        "            logging_strategy=\"steps\",\n",
        "            eval_steps=500,\n",
        "            logging_steps=500,\n",
        "            learning_rate=lr, #learning rate of the gradient descent\n",
        "            max_steps=20000,\n",
        "            load_best_model_at_end=True,\n",
        "            per_device_train_batch_size=batch_size,\n",
        "        )\n",
        "        early_stopping = transformers.EarlyStoppingCallback(5)\n",
        "        trainer = transformers.Trainer(\n",
        "            model=mlp,\n",
        "            args=trainer_args,\n",
        "            train_dataset=tokenized_data[\"train\"].select(range(10000)),\n",
        "            eval_dataset=tokenized_data[\"test\"].select(range(1000)), #make a smaller subset to evaluate on\n",
        "            compute_metrics=compute_accuracy,\n",
        "            data_collator=collator,\n",
        "            callbacks=[early_stopping]\n",
        "        )\n",
        "        trainer.train()\n",
        "        eval_result = trainer.evaluate(tokenized_data[\"test\"])\n",
        "        if eval_result[\"eval_accuracy\"] > best_accuracy:\n",
        "            best_accuracy = eval_result[\"eval_accuracy\"]\n",
        "            best_learning_rate = lr\n",
        "            best_batch_size = batch_size\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Save model \n",
        "#trainer.save_model(\"mlp_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EzCYTnfcrvN"
      },
      "source": [
        "### 3.3. Evaluation on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BG7s-yr6crGF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:00<00:00, 768.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: {'accuracy': 0.8802}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code to evaluate the final model on the test set here\n",
        "test_results = trainer.predict(tokenized_data[\"test\"].select(range(5000)))\n",
        "test_accuracy = compute_accuracy((test_results.predictions, test_results.label_ids))\n",
        "print(f\"Test accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions: \n",
            " [[-1.4783843   1.2700074 ]\n",
            " [-0.16219756  0.06732692]\n",
            " [-0.01269698 -0.06483601]\n",
            " [-1.0602162   0.89951706]\n",
            " [ 0.37185746 -0.41186056]\n",
            " [-1.1537267   0.98373985]\n",
            " [ 0.09102534 -0.15580702]\n",
            " [ 1.1402507  -1.1289095 ]\n",
            " [ 0.29495418 -0.34836176]\n",
            " [-0.6786371   0.54820937]]\n",
            "Binary predicted labels: [1 1 0 1 0 1 0 0 0 1]\n",
            "True labels: [1 1 0 1 0 1 1 0 0 1]\n"
          ]
        }
      ],
      "source": [
        "#Convert the 10 first predictions to labels \n",
        "print(\"Predictions:\", \"\\n\", test_results.predictions[:10])\n",
        "print(\"Binary predicted labels:\", np.argmax(test_results.predictions[:10], axis=-1))\n",
        "\n",
        "\n",
        "#Print first 10 true labels\n",
        "true_labels = test_results.label_ids[:10]\n",
        "print(\"True labels:\", true_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7ylOS8FdYZ5"
      },
      "source": [
        "---\n",
        "\n",
        "## 4. Results and summary\n",
        "\n",
        "### 4.1 Corpus insights\n",
        "\n",
        "The corpus \"imdb\" consists of movie reviews from IMDB: 25,000 positive and 25,000 negative reviews. Each entry consists of the review and the corresponding sentiment label. Only highly polarizing reviews are considered in this dataset - no neutral reviews are included. People have written movie reviews and given the movie a score from 1 to 10. Reviews with a score of <= 4 are labeled as negative and reviews with a score of >= 7 are labeled positive. No more than 30 reviews per movie are included.\n",
        "\n",
        "### 4.2 Results\n",
        "\n",
        "We got an evaluation accuracy of 88.02%. We performed hyperparameter tuning on a subset of the data and found the best learning rate () and batch size (), which got us to an accuracy of __.\n",
        "\n",
        "### 4.3 Relation to state of the art\n",
        "\n",
        "The state-of-the-art results of binary classifiers of the \"imdb\" dataset reach an accuracy of 96.68% with a RoBERTa-large with LlamBERT model. BERT is the standard state-of-the-art model in all NLP. BERT is a language model develped by Google so our accuracy with such a simple model can be viewed as a success. Nehal et al. got an accuracy of 86.74% in their paper using an MLP model.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Bonus Task (optional)\n",
        "\n",
        "### 5.1. Annotating out-of-domain documents\n",
        "\n",
        "(Briefly describe the chosen out-of-domain documents)\n",
        "\n",
        "(Briefly describe the process of annotation)\n",
        "\n",
        "### 5.2 Conversion into dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32DU04FndRdM"
      },
      "outputs": [],
      "source": [
        "# Your code to convert the annotations into a dataset here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ghO4JemeFKK"
      },
      "source": [
        "### 5.3. Model evaluation on out-of-domain test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tzYWQ_zeCYp"
      },
      "outputs": [],
      "source": [
        "# Your code to evaluate the model on the out-of-domain test set here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XLZlItdePfJ"
      },
      "source": [
        "### 5.4 Bonus task results\n",
        "\n",
        "(Present the results of the evaluation on the out-of-domain test set)\n",
        "\n",
        "### 5.5. Annotated data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2YJsiIGeYRe"
      },
      "outputs": [],
      "source": [
        "# Include your annotated out-of-domain data here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
